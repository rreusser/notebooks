<!doctype html>
<notebook theme="air">
  <title>Sloan Digital Sky Survey</title>
  <script id="intro" type="text/markdown">
# Sloan Digital Sky Survey

This notebook visualizes galaxies from the [Sloan Digital Sky Survey](https://www.sdss.org/) (SDSS). The data spans redshifts from ${tex`z = 0.02`} to ${tex`z = 0.5`}, corresponding to comoving distances from roughly 85 megaparsecs to over 1.9 gigaparsecs. Data loads progressively in chunks, with galaxies appearing as each chunk arrives.

Each point represents a galaxy, colored by its spectroscopic redshift. The color mapping follows the physical intuition of cosmological redshift: nearby galaxies appear blue-white while distant galaxies appear progressively redder. This mirrors how light from distant objects is stretched to longer wavelengths as it travels through expanding space.

The striking filamentary structure you see is the **cosmic web**, the large-scale structure of the universe. Galaxies cluster along dense filaments and sheets surrounding vast, nearly empty voids. This web-like pattern emerges from gravitational instability amplifying tiny density fluctuations in the early universe.
  </script>
  <script id="webgpu-setup" type="module">
import { createWebGPUContext } from './lib/webgpu-canvas.js';

const { device, canvasFormat } = await createWebGPUContext({
  optionalFeatures: ['shader-f16']
});

invalidation.then(() => device.destroy());
  </script>
  <script id="load-data" type="module">
const metadata = await fetch('./galaxies.json').then(r => r.json());

// Array of loaded chunk buffers (sparse - filled as chunks arrive)
const chunkBuffers = [];
const loadState = {
  loadedCount: 0,
  totalCount: metadata.totalCount,
  chunks: []  // Array of { buffer, count } for loaded chunks
};

// Fetch a chunk - browser auto-decompresses gzip via Content-Encoding header
async function loadChunk(chunkInfo, index) {
  const response = await fetch(`./${chunkInfo.file}`);
  const arrayBuffer = await response.arrayBuffer();
  const galaxyData = new Uint16Array(arrayBuffer);

  const buffer = device.createBuffer({
    label: `galaxy-chunk-${index}`,
    size: arrayBuffer.byteLength,
    usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
  });
  device.queue.writeBuffer(buffer, 0, galaxyData);

  return { buffer, count: chunkInfo.count };
}

// forEachLimit: process items with limited concurrency
async function forEachLimit(items, limit, fn) {
  const executing = new Set();
  for (const [index, item] of items.entries()) {
    const promise = fn(item, index).then(() => executing.delete(promise));
    executing.add(promise);
    if (executing.size >= limit) {
      await Promise.race(executing);
    }
  }
  await Promise.all(executing);
}

// Load chunks in parallel with concurrency limit
const CONCURRENCY = 4;
forEachLimit(metadata.chunks, CONCURRENCY, async (chunkInfo, index) => {
  const chunk = await loadChunk(chunkInfo, index);
  loadState.chunks.push(chunk);
  loadState.loadedCount += chunk.count;
  renderState.dirty = true;  // Trigger re-render as chunks arrive
  console.log(`Loaded chunk ${index + 1}/${metadata.chunks.length}: ${chunk.count.toLocaleString()} galaxies`);
});

invalidation.then(() => {
  for (const chunk of loadState.chunks) {
    chunk.buffer.destroy();
  }
});
  </script>
  <script id="main-canvas" type="module">
import { expandable } from './lib/expandable.js';

const dpr = window.devicePixelRatio || 1;
const canvasWidth = Math.min(800, width);
const canvasHeight = Math.max(500, canvasWidth * 0.7);

const canvas = document.createElement('canvas');
canvas.id = 'sdss-canvas';
canvas.width = Math.floor(canvasWidth * dpr);
canvas.height = Math.floor(canvasHeight * dpr);
canvas.style.width = `${canvasWidth}px`;
canvas.style.height = `${canvasHeight}px`;
canvas.style.background = '#000';

const gpuContext = canvas.getContext('webgpu');
gpuContext.configure({
  device,
  format: canvasFormat,
  alphaMode: 'premultiplied'
});

const renderState = { dirty: true };

const figure = html`<figure style="margin: 0;" id="sdss-figure">
  ${canvas}
</figure>`;

display(expandable(figure, {
  width: canvasWidth,
  height: canvasHeight,
  controls: '.sdss-controls',
  onResize(el, w, h) {
    canvas.width = Math.floor(w * dpr);
    canvas.height = Math.floor(h * dpr);
    canvas.style.width = `${w}px`;
    canvas.style.height = `${h}px`;
    gpuContext.configure({
      device,
      format: canvasFormat,
      alphaMode: 'premultiplied'
    });
    renderState.dirty = true;
  }
}));
  </script>
  <script id="controls" type="module">
const controlsContainer = html`<div class="sdss-controls"></div>`;

function ctrl(input) {
  controlsContainer.appendChild(input);
  return Generators.input(input);
}

const pointSizeInput = Inputs.range([0.5, 8], {
  value: 2,
  label: 'Point size',
  step: 0.1,
  transform: Math.log
});
const pointSize = ctrl(pointSizeInput);

const exposureInput = Inputs.range([0.1, 10], {
  value: 1.0,
  label: 'Exposure',
  step: 0.1,
  transform: Math.log
});
const exposure = ctrl(exposureInput);

const whitePointInput = Inputs.range([1, 50], {
  value: 10,
  label: 'White point',
  step: 1,
  transform: Math.log
});
const whitePoint = ctrl(whitePointInput);

display(controlsContainer);
  </script>
  <script id="loading-progress" type="module">
const progressEl = html`<div style="font-size: 14px; color: #666; margin-top: 8px;"></div>`;
display(progressEl);

let lastLoaded = 0;
const updateInterval = setInterval(() => {
  if (loadState.loadedCount !== lastLoaded) {
    lastLoaded = loadState.loadedCount;
    const pct = (loadState.loadedCount / loadState.totalCount * 100).toFixed(0);
    if (loadState.loadedCount < loadState.totalCount) {
      progressEl.textContent = `Loading: ${loadState.loadedCount.toLocaleString()} / ${loadState.totalCount.toLocaleString()} galaxies (${pct}%)`;
    } else {
      progressEl.textContent = `Loaded ${loadState.totalCount.toLocaleString()} galaxies`;
      clearInterval(updateInterval);
    }
  }
}, 100);

invalidation.then(() => clearInterval(updateInterval));
  </script>
  <script id="camera-setup" type="module">
import { createCameraController } from './lib/camera-controller.js';

const bounds = metadata.bounds;
const dataRange = Math.max(
  bounds.max[0] - bounds.min[0],
  bounds.max[1] - bounds.min[1],
  bounds.max[2] - bounds.min[2]
);

// Earth is at the origin - galaxies radiate outward from us
const center = [0, 0, 0];

// Create camera controller attached to the canvas
const cameraController = createCameraController(canvas, {
  center,
  distance: dataRange * 0.8,
  phi: 1.2,
  theta: 0.0,
  fov: Math.PI / 4,
  near: dataRange * 0.001,
  far: dataRange * 10
});

invalidation.then(() => cameraController.destroy());
  </script>
  <script id="render-pipeline" type="module">
// Shader for rendering galaxy points as instanced quads with additive blending
const shaderCode = /* wgsl */`
struct Uniforms {
  projectionView: mat4x4f,
  pointSize: f32,
  brightness: f32,
  aspectRatio: f32,
  cameraDistance: f32,
  referenceDistance: f32,
  referencePointSize: f32,
  _pad1: f32,
  _pad2: f32,
}

@group(0) @binding(0) var<uniform> uniforms: Uniforms;

struct VertexOutput {
  @builtin(position) position: vec4f,
  @location(0) redshift: f32,
  @location(1) uv: vec2f,
}

// Quad vertices for triangle strip: 4 vertices make a quad
const quadVertices = array<vec2f, 4>(
  vec2f(-1.0, -1.0),
  vec2f( 1.0, -1.0),
  vec2f(-1.0,  1.0),
  vec2f( 1.0,  1.0)
);

@vertex
fn vertexMain(
  @builtin(vertex_index) vertexIndex: u32,
  // Instance data: float16x4 (x, y, z, normalized_redshift)
  @location(0) instanceData: vec4<f32>
) -> VertexOutput {
  var output: VertexOutput;

  // Get quad corner from vertex index
  let corner = quadVertices[vertexIndex];

  // Transform galaxy position to clip space
  let worldPos = vec4f(instanceData.xyz, 1.0);
  let clipPos = uniforms.projectionView * worldPos;

  // Expand quad in screen space (size in pixels)
  let size = uniforms.pointSize / vec2f(uniforms.aspectRatio, 1.0);
  let offset = corner * size * clipPos.w * 0.001;

  output.position = clipPos + vec4f(offset, 0.0, 0.0);
  output.redshift = instanceData.w;
  output.uv = corner;

  return output;
}

// Attempt a physically-motivated color for redshift
// Maps normalized redshift (0-1) to a color that suggests
// the cosmological redshift of light
fn redshiftColor(z: f32) -> vec3f {
  // Use a perceptually smooth color ramp from blue-white to deep red
  // Low z (nearby): bright blue-white (hot stars)
  // High z (distant): deep red (redshifted light)

  let t = clamp(z, 0.0, 1.0);

  // Blue-white to red gradient
  let blue = vec3f(0.7, 0.85, 1.0);   // Nearby: blue-white
  let red = vec3f(1.0, 0.2, 0.05);    // Distant: deep red

  // Use a power curve for more dramatic color separation
  let curve = pow(t, 0.7);

  return mix(blue, red, curve);
}

@fragment
fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
  // Circular falloff from center of point
  let dist = length(input.uv);
  if (dist > 1.0) {
    discard;
  }

  // Soft gaussian-like falloff for nice glow effect
  let falloff = exp(-dist * dist * 2.0);

  // Scale brightness by camera distance to maintain perceived brightness when zooming
  // As we zoom out, points become denser on screen, so reduce brightness to compensate
  // Use gamma-aware scaling: perceived brightness ~ luminance^(1/gamma)
  let distanceRatio = uniforms.cameraDistance / uniforms.referenceDistance;
  let distanceScale = pow(distanceRatio, -0.9);  // Inverse: dimmer when zoomed out

  // Compensate for point size: use linear scaling rather than area (size²)
  // because the gaussian falloff concentrates perceived brightness at the center
  let sizeRatio = uniforms.pointSize / uniforms.referencePointSize;
  let sizeScale = 1.0 / sizeRatio;

  let color = redshiftColor(input.redshift);
  let intensity = uniforms.brightness * falloff * distanceScale * sizeScale;

  return vec4f(color * intensity, intensity);
}
`;

const shaderModule = device.createShaderModule({
  label: 'galaxy-shader',
  code: shaderCode
});

const uniformBuffer = device.createBuffer({
  label: 'galaxy-uniforms',
  size: 96, // mat4x4f (64) + 8 floats (32)
  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
});

const bindGroupLayout = device.createBindGroupLayout({
  entries: [{
    binding: 0,
    visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,
    buffer: { type: 'uniform' }
  }]
});

const bindGroup = device.createBindGroup({
  layout: bindGroupLayout,
  entries: [{
    binding: 0,
    resource: { buffer: uniformBuffer }
  }]
});

const pipelineLayout = device.createPipelineLayout({
  bindGroupLayouts: [bindGroupLayout]
});

const pipeline = device.createRenderPipeline({
  label: 'galaxy-pipeline',
  layout: pipelineLayout,
  vertex: {
    module: shaderModule,
    entryPoint: 'vertexMain',
    buffers: [{
      // Instance buffer: one entry per galaxy
      arrayStride: 8, // 4 x float16
      stepMode: 'instance',
      attributes: [{
        shaderLocation: 0,
        offset: 0,
        format: 'float16x4'
      }]
    }]
  },
  fragment: {
    module: shaderModule,
    entryPoint: 'fragmentMain',
    targets: [{
      format: 'rgba16float',  // Render to HDR texture
      blend: {
        // Additive blending for overlapping points
        color: {
          srcFactor: 'src-alpha',
          dstFactor: 'one',
          operation: 'add'
        },
        alpha: {
          srcFactor: 'one',
          dstFactor: 'one',
          operation: 'add'
        }
      }
    }]
  },
  primitive: {
    topology: 'triangle-strip'
  }
});

// Tonemap shader with extended Reinhard and exposure control
const tonemapShaderCode = /* wgsl */`
@group(0) @binding(0) var hdrTexture: texture_2d<f32>;
@group(0) @binding(1) var texSampler: sampler;
@group(0) @binding(2) var<uniform> tonemapParams: vec4f;  // x=exposure, y=whitePoint

struct VertexOutput {
  @builtin(position) position: vec4f,
  @location(0) uv: vec2f,
}

@vertex
fn vertexMain(@builtin(vertex_index) vertexIndex: u32) -> VertexOutput {
  // Fullscreen triangle
  var pos = array<vec2f, 3>(
    vec2f(-1.0, -1.0),
    vec2f( 3.0, -1.0),
    vec2f(-1.0,  3.0)
  );
  var output: VertexOutput;
  output.position = vec4f(pos[vertexIndex], 0.0, 1.0);
  output.uv = (pos[vertexIndex] + 1.0) * 0.5;
  output.uv.y = 1.0 - output.uv.y;  // Flip Y for texture coordinates
  return output;
}

// Extended Reinhard tonemap: x * (1 + x/white²) / (1 + x)
// This allows values up to 'white' to map close to 1.0
fn reinhardExtended(x: vec3f, white: f32) -> vec3f {
  let white2 = white * white;
  return x * (1.0 + x / white2) / (1.0 + x);
}

@fragment
fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
  let hdr = textureSample(hdrTexture, texSampler, input.uv);

  let exposure = tonemapParams.x;
  let whitePoint = tonemapParams.y;

  // Apply exposure and tonemap
  let exposed = hdr.rgb * exposure;
  let ldr = reinhardExtended(exposed, whitePoint);

  return vec4f(ldr, 1.0);
}
`;

const tonemapShaderModule = device.createShaderModule({
  label: 'tonemap-shader',
  code: tonemapShaderCode
});

const tonemapUniformBuffer = device.createBuffer({
  label: 'tonemap-uniforms',
  size: 16,  // vec4f
  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
});

const tonemapBindGroupLayout = device.createBindGroupLayout({
  entries: [
    { binding: 0, visibility: GPUShaderStage.FRAGMENT, texture: { sampleType: 'float' } },
    { binding: 1, visibility: GPUShaderStage.FRAGMENT, sampler: { type: 'filtering' } },
    { binding: 2, visibility: GPUShaderStage.FRAGMENT, buffer: { type: 'uniform' } }
  ]
});

const tonemapPipelineLayout = device.createPipelineLayout({
  bindGroupLayouts: [tonemapBindGroupLayout]
});

const tonemapPipeline = device.createRenderPipeline({
  label: 'tonemap-pipeline',
  layout: tonemapPipelineLayout,
  vertex: {
    module: tonemapShaderModule,
    entryPoint: 'vertexMain'
  },
  fragment: {
    module: tonemapShaderModule,
    entryPoint: 'fragmentMain',
    targets: [{ format: canvasFormat }]
  },
  primitive: {
    topology: 'triangle-list'
  }
});

const hdrSampler = device.createSampler({
  magFilter: 'linear',
  minFilter: 'linear'
});

// HDR texture state - will be created/resized in render loop
const hdrState = {
  texture: null,
  bindGroup: null,
  width: 0,
  height: 0
};

function ensureHdrTexture(width, height) {
  if (hdrState.width === width && hdrState.height === height && hdrState.texture) {
    return;
  }

  if (hdrState.texture) {
    hdrState.texture.destroy();
  }

  hdrState.texture = device.createTexture({
    label: 'hdr-texture',
    size: [width, height],
    format: 'rgba16float',
    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING
  });

  hdrState.bindGroup = device.createBindGroup({
    layout: tonemapBindGroupLayout,
    entries: [
      { binding: 0, resource: hdrState.texture.createView() },
      { binding: 1, resource: hdrSampler },
      { binding: 2, resource: { buffer: tonemapUniformBuffer } }
    ]
  });

  hdrState.width = width;
  hdrState.height = height;
}

invalidation.then(() => {
  uniformBuffer.destroy();
  tonemapUniformBuffer.destroy();
  if (hdrState.texture) hdrState.texture.destroy();
});
  </script>
  <script id="render-loop" type="module">
import { createFrameLoop } from './lib/frame-loop.js';

// Reactive dependencies - when these change, this cell re-runs
pointSize; exposure; whitePoint;

// Mark dirty so we re-render with new control values
renderState.dirty = true;

// Pre-allocate uniform data buffer
const uniformData = new ArrayBuffer(96);
const uniformF32 = new Float32Array(uniformData);

// Tonemap uniform buffer
const tonemapData = new Float32Array(4);

// Reference distance for brightness scaling (initial camera distance)
const referenceDistance = dataRange * 0.8;

const loop = createFrameLoop(() => {
  const aspectRatio = canvas.width / canvas.height;
  const { projectionView, dirty: cameraDirty } = cameraController.update(aspectRatio);

  if (!renderState.dirty && !cameraDirty) return;
  if (loadState.chunks.length === 0) return;  // Nothing to draw yet

  // Ensure HDR texture matches canvas size
  ensureHdrTexture(canvas.width, canvas.height);

  // Update uniforms
  uniformF32.set(projectionView, 0);
  uniformF32[16] = pointSize * dpr;
  uniformF32[17] = 0.5;  // Fixed base brightness (exposure controls overall level)
  uniformF32[18] = aspectRatio;
  uniformF32[19] = cameraController.state.distance;
  uniformF32[20] = referenceDistance;
  uniformF32[21] = 2.0 * dpr;  // Reference point size (default value)
  device.queue.writeBuffer(uniformBuffer, 0, uniformData);

  const encoder = device.createCommandEncoder();

  // Pass 1: Render galaxies to HDR texture with additive blending
  const hdrPass = encoder.beginRenderPass({
    colorAttachments: [{
      view: hdrState.texture.createView(),
      loadOp: 'clear',
      storeOp: 'store',
      clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 0.0 }
    }]
  });

  hdrPass.setPipeline(pipeline);
  hdrPass.setBindGroup(0, bindGroup);

  // Draw each loaded chunk with a separate draw call
  for (const chunk of loadState.chunks) {
    hdrPass.setVertexBuffer(0, chunk.buffer);
    hdrPass.draw(4, chunk.count);
  }

  hdrPass.end();

  // Update tonemap uniforms
  tonemapData[0] = exposure;
  tonemapData[1] = whitePoint;
  device.queue.writeBuffer(tonemapUniformBuffer, 0, tonemapData);

  // Pass 2: Tonemap HDR to screen
  const screenPass = encoder.beginRenderPass({
    colorAttachments: [{
      view: gpuContext.getCurrentTexture().createView(),
      loadOp: 'clear',
      storeOp: 'store',
      clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 }
    }]
  });

  screenPass.setPipeline(tonemapPipeline);
  screenPass.setBindGroup(0, hdrState.bindGroup);
  screenPass.draw(3);  // Fullscreen triangle

  screenPass.end();

  device.queue.submit([encoder.finish()]);

  renderState.dirty = false;
});

invalidation.then(() => loop.cancel());
  </script>
  <script id="physics" type="text/markdown">
## The physics of cosmological redshift

When we observe distant galaxies, their light is stretched to longer wavelengths by the expansion of space itself. This **cosmological redshift** is quantified by the parameter ${tex`z`}:

${tex.block`z = \frac{\lambda_{\text{observed}} - \lambda_{\text{emitted}}}{\lambda_{\text{emitted}}}`}

A galaxy with ${tex`z = 0.1`} has its light stretched by 10%. The relationship between redshift and distance depends on the cosmological model. For the ${tex`\Lambda`}CDM model used here, distance is computed using the Planck 2018 cosmological parameters.

The data in this visualization covers ${tex`z = 0.02`} to ${tex`z = 0.5`}. At these redshifts, we're looking at galaxies whose light left between 270 million and over 5 billion years ago.
  </script>
  <script id="cosmic-web" type="text/markdown">
## The cosmic web

The large-scale structure visible in this data is a direct consequence of gravitational instability. Shortly after the Big Bang, the universe was almost perfectly uniform, with density fluctuations of only about 1 part in 100,000. Gravity amplified these fluctuations over billions of years: dense regions pulled in more matter, becoming denser still, while underdense regions emptied out into voids.

The result is the cosmic web: a network of **filaments** (dense, thread-like structures where galaxies cluster), **sheets** (thin walls of galaxies), **nodes** (massive galaxy clusters where filaments intersect), and **voids** (vast, nearly empty regions bounded by filaments and sheets).

The SDSS data captures only a slice of this structure, limited by the survey's sky coverage. The conical shape reflects the survey geometry: we observe a cone of the sky extending outward from Earth.
  </script>
</notebook>
