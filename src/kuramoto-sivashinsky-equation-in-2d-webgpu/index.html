<!doctype html>
<notebook theme="air">
  <title>Kuramoto-Sivashinsky Equation in 2D (WebGPU)</title>

  <script id="intro" type="module">
    display(md`# Kuramoto-Sivashinsky Equation in 2D (WebGPU)

This notebook implements on the GPU a two-dimensional solution of the [Kuramoto-Sivashinsky equation](https://encyclopediaofmath.org/wiki/Kuramoto-Sivashinsky_equation) (KSE),

${tex.block`u_t + \frac{1}{2}|\nabla u|^2 + \nabla^2 u + \nabla^4 u = 0.`}

The KSE is one of the simplest partial differential equations to show complicated dynamics, displaying chaotic behavior as the size of the domain increases.`);
  </script>

  <!-- Controls -->
  <script id="controls" type="module">
    const simulateInput = Inputs.toggle({ label: 'Simulate', value: true });
    const simulate = view(simulateInput);
    display(html`<button id="restart-btn">Restart</button>`);
  </script>

  <script id="domain-controls" type="module">
    const LxInput = Inputs.range([1, 128], {
      step: 0.5,
      value: 64,
      label: html`Domain size, ${tex`L_x`}`
    });
    const Lx = view(LxInput);

    const aspectRatioInput = Inputs.range([0.1, 10], {
      step: 0.01,
      value: 1,
      label: html`Aspect ratio, ${tex`L_x / L_y`}`
    });
    const aspectRatio = view(aspectRatioInput);
  </script>

  <script id="ic-controls" type="module">
    const nInput = Inputs.range([1, 8], {
      step: 1,
      value: 1,
      label: 'Initial condition periods, n'
    });
    const n = view(nInput);
  </script>

  <script id="vis-controls" type="module">
    const rangeInput = Inputs.range([0.5, 20], {
      step: 0.5,
      value: 14,
      label: 'Colorscale threshold'
    });
    const range = view(rangeInput);

    const colorscaleNameInput = Inputs.select(
      ['Viridis', 'Magma', 'Inferno', 'Plasma', 'Cividis', 'Greys'],
      { value: 'Magma', label: 'Colorscale' }
    );
    const colorscaleName = view(colorscaleNameInput);

    const invertInput = Inputs.toggle({ label: 'Invert colorscale', value: false });
    const invert = view(invertInput);
  </script>

  <script id="domain-info" type="module">
    const L = [Lx, Lx / aspectRatio];
    const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];

    display(md`We solve the problem in the doubly periodic domain, ${tex`[0, ${L[0].toFixed(1)}] \times [0, ${L[1].toFixed(1)}]`}.

The factors ${tex`\nu_1`} and ${tex`\nu_2`} describe the length scale:
- ${tex`\nu_1 = (\pi/L_x)^2 = ${nu[0].toFixed(6)}`}
- ${tex`\nu_2 = (\pi/L_y)^2 = ${nu[1].toFixed(6)}`}`);
  </script>

  <!-- WebGPU Context - runs once -->
  <script id="webgpu-context" type="module">
    import { createWebGPUContext } from './webgpu-context.js';

    const context = await createWebGPUContext();
    const device = context.device;
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();

    invalidation.then(() => device.destroy());
  </script>

  <!-- Constants - no dependencies -->
  <script id="constants" type="module">
    const N = 256;
    const vec2Size = N * N * 2 * 4;
    const vec4Size = N * N * 4 * 4;
    const workgroups = Math.ceil(N / 16);
    const bufferUsage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST;
    const dx = [2 * Math.PI / N, 2 * Math.PI / N];
  </script>

  <!-- Pipelines - depends only on device -->
  <script id="pipelines" type="module">
    import { createKSPipelines } from './pipeline.js';
    import { createFFTPipelines, executeFFT2D } from './fft.js';

    const pipelines = await createKSPipelines(device, canvasFormat);
    const fftPipelines = await createFFTPipelines(device);

    function runFFT2D(input, output, tempBuffers, forward) {
      executeFFT2D({
        device,
        pipelines: fftPipelines,
        input,
        output,
        temp: tempBuffers,
        N,
        forward,
        splitNormalization: true
      });
    }
  </script>

  <!-- Buffer allocation - depends only on device and constants -->
  <script id="buffers" type="module">
    // Vhat buffers: 3 time levels for BDF2
    const Vhat = [0, 1, 2].map(i => device.createBuffer({
      label: `Vhat[${i}]`,
      size: vec2Size,
      usage: bufferUsage
    }));

    // ABhat buffers: nonlinear terms at 2 time levels
    const ABhat = [0, 1].map(i => device.createBuffer({
      label: `ABhat[${i}]`,
      size: vec4Size,
      usage: bufferUsage
    }));

    // Working buffers
    const V = device.createBuffer({ label: 'V', size: vec2Size, usage: bufferUsage });
    const temp = [0, 1].map(i => device.createBuffer({ label: `temp[${i}]`, size: vec2Size, usage: bufferUsage }));
    const tempVec4 = device.createBuffer({ label: 'tempVec4', size: vec4Size, usage: bufferUsage });
    const VxVy = device.createBuffer({ label: 'VxVy', size: vec2Size, usage: bufferUsage });
    const A = device.createBuffer({ label: 'A', size: vec2Size, usage: bufferUsage });
    const B = device.createBuffer({ label: 'B', size: vec2Size, usage: bufferUsage });
    const Ahat = device.createBuffer({ label: 'Ahat', size: vec2Size, usage: bufferUsage });
    const Bhat = device.createBuffer({ label: 'Bhat', size: vec2Size, usage: bufferUsage });
    const Vreal = device.createBuffer({ label: 'Vreal', size: vec2Size, usage: bufferUsage });
  </script>

  <!-- Uniform buffers - depends only on device -->
  <script id="uniform-buffers" type="module">
    const initParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const diffParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    {
      const data = new ArrayBuffer(16);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 2).set(dx);
      device.queue.writeBuffer(diffParamsBuffer, 0, data);
    }

    const bdfParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const extractRealParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(extractRealParamsBuffer, 0, new Uint32Array([N, N]));

    const visParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
  </script>

  <!-- Colorscale data - depends only on device -->
  <script id="colorscale-data" type="module">
    function generateColorscale(interpolator) {
      const data = new Uint8Array(256 * 4);
      for (let i = 0; i < 256; i++) {
        const t = i / 255;
        const color = d3.rgb(interpolator(t));
        data[i * 4] = Math.round(color.r);
        data[i * 4 + 1] = Math.round(color.g);
        data[i * 4 + 2] = Math.round(color.b);
        data[i * 4 + 3] = 255;
      }
      return data;
    }

    const colorscaleData = {
      Viridis: generateColorscale(d3.interpolateViridis),
      Magma: generateColorscale(d3.interpolateMagma),
      Inferno: generateColorscale(d3.interpolateInferno),
      Plasma: generateColorscale(d3.interpolatePlasma),
      Cividis: generateColorscale(d3.interpolateCividis),
      Greys: generateColorscale(d3.interpolateGreys)
    };

    const colorscaleTexture = device.createTexture({
      size: [256, 1],
      format: 'rgba8unorm',
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
    });

    const colorscaleSampler = device.createSampler({
      magFilter: 'linear',
      minFilter: 'linear'
    });

    // Initialize with default
    device.queue.writeTexture(
      { texture: colorscaleTexture },
      colorscaleData['Magma'],
      { bytesPerRow: 256 * 4 },
      [256, 1]
    );
  </script>

  <!-- Canvas - created once, no aspectRatio dependency -->
  <script id="canvas" type="module">
    const maxSize = 512;

    const canvas = document.createElement('canvas');
    canvas.width = maxSize;
    canvas.height = maxSize;
    canvas.style.width = `${maxSize}px`;
    canvas.style.height = `${maxSize}px`;
    canvas.style.imageRendering = 'pixelated';

    const gpuContext = canvas.getContext('webgpu');
    gpuContext.configure({
      device,
      format: canvasFormat,
      alphaMode: 'opaque'
    });

    // Function to resize canvas without recreating it
    function resizeCanvas(ar) {
      let w, h;
      if (ar >= 1) {
        w = maxSize;
        h = Math.floor(maxSize / ar);
      } else {
        h = maxSize;
        w = Math.floor(maxSize * ar);
      }
      canvas.width = w;
      canvas.height = h;
      canvas.style.width = `${w}px`;
      canvas.style.height = `${h}px`;
      gpuContext.configure({
        device,
        format: canvasFormat,
        alphaMode: 'opaque'
      });
    }

    display(canvas);
  </script>

  <!-- Canvas resize on aspect ratio change - doesn't restart simulation -->
  <script id="canvas-resize" type="module">
    aspectRatio;
    resizeCanvas(aspectRatio);
    if (simState && simState.initialized) render();
  </script>

  <!-- Simulation state and params - mutable, not reactive -->
  <script id="sim-state" type="module">
    const simState = {
      timeLevel: 0,
      stepCount: 0,
      initialized: false
    };

    // Shared params object - updated reactively but read without creating dependencies
    const simParams = {
      Lx: 64,
      aspectRatio: 1,
      n: 1,
      range: 14,
      colorscaleName: 'Magma',
      invert: false
    };
  </script>

  <!-- Update simParams when inputs change - this cell depends on inputs but sim-functions doesn't -->
  <script id="params-update" type="module">
    Lx; aspectRatio; n; range; colorscaleName; invert;
    simParams.Lx = Lx;
    simParams.aspectRatio = aspectRatio;
    simParams.n = n;
    simParams.range = range;
    simParams.colorscaleName = colorscaleName;
    simParams.invert = invert;
  </script>

  <!-- Simulation functions - reads from simParams, no direct input dependencies -->
  <script id="sim-functions" type="module">
    import { readComplexBuffer2D } from './debug.js';

    // Get current simulation parameters from simParams
    function getParams() {
      const Lx = simParams.Lx;
      const L = [Lx, Lx / simParams.aspectRatio];
      const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];
      const dt = 0.18 * nu[0];
      return { L, nu, dt, n: simParams.n, dx };
    }

    // Update uniform buffers with current params
    function updateUniforms() {
      const { nu, dt, n } = getParams();

      // Init params
      const initData = new ArrayBuffer(16);
      new Uint32Array(initData, 0, 2).set([N, N]);
      new Float32Array(initData, 8, 1).set([n]);
      device.queue.writeBuffer(initParamsBuffer, 0, initData);

      // BDF params
      const bdfData = new ArrayBuffer(32);
      new Uint32Array(bdfData, 0, 2).set([N, N]);
      new Float32Array(bdfData, 8, 2).set(dx);
      new Float32Array(bdfData, 16, 1).set([dt]);
      new Float32Array(bdfData, 24, 2).set(nu);
      device.queue.writeBuffer(bdfParamsBuffer, 0, bdfData);
    }

    // Update visualization uniforms from simParams
    function updateVisUniforms() {
      const data = new ArrayBuffer(32);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 2).set([-simParams.range, simParams.range]);
      new Uint32Array(data, 16, 1).set([simParams.invert ? 1 : 0]);
      device.queue.writeBuffer(visParamsBuffer, 0, data);

      // Update colorscale texture
      const csData = colorscaleData[simParams.colorscaleName];
      if (csData) {
        device.queue.writeTexture(
          { texture: colorscaleTexture },
          csData,
          { bytesPerRow: 256 * 4 },
          [256, 1]
        );
      }
    }

    // Initialize simulation
    async function initialize() {
      updateUniforms();

      const initBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.initialize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: initParamsBuffer } }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginComputePass();
      pass.setPipeline(pipelines.initialize);
      pass.setBindGroup(0, initBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(V, Vhat[0], temp, true);

      const enc2 = device.createCommandEncoder();
      enc2.copyBufferToBuffer(Vhat[0], 0, Vhat[1], 0, vec2Size);
      device.queue.submit([enc2.finish()]);
      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = 1;
      simState.stepCount = 0;
      simState.initialized = true;
    }

    // Compute nonlinear terms
    async function computeNonlinearTo(vhatIdx, abhatIdx) {
      const VhatIn = Vhat[vhatIdx];
      const ABhatOut = ABhat[abhatIdx];

      const diffBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.differentiate,
        entries: [
          { binding: 0, resource: { buffer: VhatIn } },
          { binding: 1, resource: { buffer: tempVec4 } },
          { binding: 2, resource: { buffer: diffParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.differentiate);
      pass.setBindGroup(0, diffBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);
      await device.queue.onSubmittedWorkDone();

      const staging = device.createBuffer({
        size: vec4Size,
        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST
      });
      enc = device.createCommandEncoder();
      enc.copyBufferToBuffer(tempVec4, 0, staging, 0, vec4Size);
      device.queue.submit([enc.finish()]);
      await device.queue.onSubmittedWorkDone();
      await staging.mapAsync(GPUMapMode.READ);

      const tempVec4Data = new Float32Array(staging.getMappedRange().slice(0));
      staging.unmap();
      staging.destroy();

      const mixedVec2 = new Float32Array(N * N * 2);
      for (let i = 0; i < N * N; i++) {
        mixedVec2[i * 2] = tempVec4Data[i * 4 + 2];
        mixedVec2[i * 2 + 1] = tempVec4Data[i * 4 + 3];
      }
      device.queue.writeBuffer(VxVy, 0, mixedVec2);

      runFFT2D(VxVy, VxVy, temp, false);
      await device.queue.onSubmittedWorkDone();

      const stagingVxVy = device.createBuffer({
        size: vec2Size,
        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST
      });
      enc = device.createCommandEncoder();
      enc.copyBufferToBuffer(VxVy, 0, stagingVxVy, 0, vec2Size);
      device.queue.submit([enc.finish()]);
      await device.queue.onSubmittedWorkDone();
      await stagingVxVy.mapAsync(GPUMapMode.READ);

      const VxVyData = new Float32Array(stagingVxVy.getMappedRange().slice(0));
      stagingVxVy.unmap();
      stagingVxVy.destroy();

      const A_data = new Float32Array(N * N * 2);
      const B_data = new Float32Array(N * N * 2);
      for (let i = 0; i < N * N; i++) {
        const Vx = VxVyData[i * 2];
        const Vy = VxVyData[i * 2 + 1];
        A_data[i * 2] = -0.5 * Vx * Vx;
        B_data[i * 2] = -0.5 * Vy * Vy;
      }
      device.queue.writeBuffer(A, 0, A_data);
      device.queue.writeBuffer(B, 0, B_data);

      runFFT2D(A, Ahat, temp, true);
      runFFT2D(B, Bhat, temp, true);
      await device.queue.onSubmittedWorkDone();

      const stagingA = device.createBuffer({ size: vec2Size, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
      const stagingB = device.createBuffer({ size: vec2Size, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
      enc = device.createCommandEncoder();
      enc.copyBufferToBuffer(Ahat, 0, stagingA, 0, vec2Size);
      enc.copyBufferToBuffer(Bhat, 0, stagingB, 0, vec2Size);
      device.queue.submit([enc.finish()]);
      await device.queue.onSubmittedWorkDone();

      await stagingA.mapAsync(GPUMapMode.READ);
      await stagingB.mapAsync(GPUMapMode.READ);
      const AhatData = new Float32Array(stagingA.getMappedRange().slice(0));
      const BhatData = new Float32Array(stagingB.getMappedRange().slice(0));
      stagingA.unmap();
      stagingB.unmap();
      stagingA.destroy();
      stagingB.destroy();

      const ABhat_data = new Float32Array(N * N * 4);
      for (let i = 0; i < N * N; i++) {
        ABhat_data[i * 4] = AhatData[i * 2];
        ABhat_data[i * 4 + 1] = AhatData[i * 2 + 1];
        ABhat_data[i * 4 + 2] = BhatData[i * 2];
        ABhat_data[i * 4 + 3] = BhatData[i * 2 + 1];
      }
      device.queue.writeBuffer(ABhatOut, 0, ABhat_data);
    }

    // Run one BDF2 step
    async function step() {
      if (!simState.initialized) return;

      // Update BDF params in case Lx changed
      updateUniforms();

      const idx0 = (simState.timeLevel - 1 + 3) % 3;
      const idx1 = simState.timeLevel % 3;
      const idx2 = (simState.timeLevel + 1) % 3;

      await computeNonlinearTo(idx0, 0);
      await computeNonlinearTo(idx1, 1);

      const bdfBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.bdfUpdate,
        entries: [
          { binding: 0, resource: { buffer: Vhat[idx0] } },
          { binding: 1, resource: { buffer: Vhat[idx1] } },
          { binding: 2, resource: { buffer: ABhat[0] } },
          { binding: 3, resource: { buffer: ABhat[1] } },
          { binding: 4, resource: { buffer: Vhat[idx2] } },
          { binding: 5, resource: { buffer: bdfParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.bdfUpdate);
      pass.setBindGroup(0, bdfBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vhat[idx2], V, temp, false);

      const extractBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.extractReal,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: Vreal } },
          { binding: 2, resource: { buffer: extractRealParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.extractReal);
      pass.setBindGroup(0, extractBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vreal, Vhat[idx2], temp, true);

      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = (simState.timeLevel + 1) % 3;
      simState.stepCount++;
    }

    // Render current state
    function render() {
      if (!simState.initialized) return;

      updateVisUniforms();

      const currentVhat = Vhat[simState.timeLevel % 3];
      runFFT2D(currentVhat, V, temp, false);

      const visBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.visualize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: visParamsBuffer } },
          { binding: 2, resource: colorscaleTexture.createView() },
          { binding: 3, resource: colorscaleSampler }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginRenderPass({
        colorAttachments: [{
          view: gpuContext.getCurrentTexture().createView(),
          loadOp: 'clear',
          storeOp: 'store',
          clearValue: { r: 0, g: 0, b: 0, a: 1 }
        }]
      });
      pass.setPipeline(pipelines.visualize);
      pass.setBindGroup(0, visBindGroup);
      pass.draw(6);
      pass.end();
      device.queue.submit([enc.finish()]);
    }
  </script>

  <!-- Initial run -->
  <script id="init-run" type="module">
    await initialize();
    render();

    // Setup restart button
    document.getElementById('restart-btn').onclick = async () => {
      await initialize();
      render();
    };
  </script>

  <!-- Animation loop -->
  <script id="animation" type="module">
    let animRunning = true;

    async function animationLoop() {
      if (!animRunning) return;

      if (simulate && simState.initialized) {
        for (let i = 0; i < 2; i++) {
          await step();
        }
        render();
      }
      requestAnimationFrame(animationLoop);
    }

    animationLoop();

    invalidation.then(() => {
      animRunning = false;
    });
  </script>

  <!-- Reactive render on vis param changes -->
  <script id="vis-reactive" type="module">
    // Re-render when vis params change (params-update already updated simParams)
    range; colorscaleName; invert;
    if (simState && simState.initialized) render();
  </script>

  <!-- Status display with requestAnimationFrame -->
  <script id="status" type="module">
    const statusEl = html`<p><em>Step: <span id="step-count">0</span></em></p>`;
    display(statusEl);

    let statusRunning = true;

    function updateStatus() {
      if (!statusRunning) return;
      const el = document.getElementById('step-count');
      if (el) el.textContent = simState.stepCount;
      requestAnimationFrame(updateStatus);
    }

    updateStatus();

    invalidation.then(() => {
      statusRunning = false;
    });
  </script>
</notebook>
