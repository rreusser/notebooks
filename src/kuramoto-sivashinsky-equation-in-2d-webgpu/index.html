<!doctype html>
<notebook theme="air">
  <title>Kuramoto-Sivashinsky Equation in 2D (WebGPU)</title>
  <script id="1" type="text/markdown">
    # Kuramoto-Sivashinsky Equation in 2D (WebGPU)

    This notebook implements on the GPU a two-dimensional solution of the [Kuramoto-Sivashinsky equation](https://encyclopediaofmath.org/wiki/Kuramoto-Sivashinsky_equation) (KSE),

    ${tex.block`u_t + \frac{1}{2}|\nabla u|^2 + \nabla^2 u + \nabla^4 u = 0.`}

    The KSE arises in a number of contexts and was rediscovered by Kuramoto while researching diffusion-induced flame front instabilities.
  </script>
  <script id="2" type="text/markdown">
    The KSE is one of the simplest partial differential equations to show complicated dynamics, displaying chaotic behavior as the size of the domain increases. Observe that if ${tex`\nu_1`} or ${tex`\nu_2`}, which represent the size of a wavelength relative to the size of the domain, are greater than one, the chaotic behavior disappears along the short dimension and the solution essentially becomes a one-dimensional solution.
  </script>
  <script id="3" type="module">
    // With hierarchical FFT, we can support sizes up to maxWorkgroupSize^2
    // For N > maxWorkgroupSize, we decompose N = R × C where C ≤ maxWorkgroupSize
    const maxWorkgroupSize = device.limits.maxComputeWorkgroupSizeX;

    // All sizes we want to support
    const allSizes = [32, 64, 128, 256, 512, 1024];

    // Filter to sizes that are either:
    // - ≤ maxWorkgroupSize (handled by simple FFT)
    // - Decomposable as R × C where C ≤ maxWorkgroupSize and R is power of 2
    const validSizes = allSizes.filter(n => {
      if (n <= maxWorkgroupSize) return true;
      // For large N, check if we can factor it appropriately
      const C = maxWorkgroupSize;
      const R = n / C;
      return Number.isInteger(R) && (R & (R - 1)) === 0;
    });

    const gridSizeOptions = validSizes.map(n => `${n}×${n}`);

    // Default to 512 for testing hierarchical FFT
    const defaultN = 512;

    const NInput = Inputs.select(gridSizeOptions, {
      value: `${defaultN}×${defaultN}`,
      label: 'Grid size, N'
    });
    const NString = view(NInput);
  </script>
  <script id="3b" type="module">
    const N = parseInt(NString.split('×')[0]);
  </script>
  <script id="4" type="module">
    // Max domain size scales with grid resolution (N/2)
    const maxLx = N / 2;
    const LxInput = Inputs.range([1, maxLx], {
      step: 0.5,
      value: Math.min(64, maxLx),
      label: html`Domain size, ${tex`L_x`}`
    });
    const Lx = view(LxInput);

    const aspectRatioInput = Inputs.range([1.0, 10], {
      step: 0.01,
      value: 1,
      transform: Math.log,
      label: html`Aspect ratio, ${tex`L_x / L_y`}`
    });
    const aspectRatio = view(aspectRatioInput);
    const nInput = Inputs.range([1, 8], {
      step: 1,
      value: 1,
      label: 'Initial condition periods, n'
    });
    const n = view(nInput);
  </script>
  <script id="6" type="module">
    const simulateInput = Inputs.toggle({ label: 'Simulate', value: ['Simulate'] });
    const simulate = view(simulateInput);
    const restartInput = Inputs.button('Restart');
    const restart = view(restartInput);
  </script>
  <script id="7" type="module">
    canvas.style.maxWidth = '100%';
    canvas.style.height = 'auto';
    const figure = html`<figure style="display: flex; justify-content: center; margin: 0;">${canvas}</figure>`;
    display(figure);
  </script>
  <script id="8" type="module">
    display(statusEl);
  </script>
  <script id="9" type="module">
    const contrastInput = Inputs.range([0, 1], {
      step: 0.01,
      value: 0.5,
      label: 'Contrast'
    });
    const contrast = view(contrastInput);

    const colorscaleNameInput = Inputs.select(
      ['Viridis', 'Magma', 'Inferno', 'Plasma', 'Cividis', 'Greys'],
      { value: 'Magma', label: 'Colorscale' }
    );
    const colorscaleName = view(colorscaleNameInput);

    const invertInput = Inputs.toggle({ label: 'Invert colorscale', value: true });
    const invert = view(invertInput);
  </script>
  <script id="10" type="module">
    const L = [Lx, Lx / aspectRatio];
    const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];

    display(md`We solve the problem in the doubly periodic domain, ${tex`[0, ${L[0].toFixed(1)}] \times [0, ${L[1].toFixed(1)}]`}.

    The factors ${tex`\nu_1`} and ${tex`\nu_2`} describe the length scale. Chaotic behavior happens when they are very small, while fundamental changes in the type of behavior happen when they are closer to unity.
    - ${tex`\nu_1 = (\pi/L_x)^2 = ${nu[0].toFixed(6)}`}
    - ${tex`\nu_2 = (\pi/L_y)^2 = ${nu[1].toFixed(6)}`}`);
  </script>
  <script id="11" type="text/markdown">
    ## Solution method

    This notebook follows the solution method outlined in [Kalogirou's thesis](https://spiral.imperial.ac.uk/bitstream/10044/1/25067/1/Kalogirou-A-2013-PhD-Thesis.pdf), particularly equations (F.8) - (F.10). The solution uses an implicit-explicit [Backward Differentiation Formula](https://en.wikipedia.org/wiki/Backward_differentiation_formula) in the spatial frequency domain.
  </script>
  <script id="12" type="text/markdown">
    The equation is solved in the spatial frequency domain, with the exception of the nonlinear term ${tex`\frac{1}{2}|\nabla u|^2`} which requires computing the gradient while transforming back to the spatial domain, then squaring, then transforming back to the frequency domain.
  </script>
  <script id="13" type="text/markdown">
    A few implementation notes:

    - Equation (F.10) seems to be missing a factor of ${tex`dt`} in the biharmonic term.
    - Since all terms include derivatives, the offset of ${tex`u`} has no effect and can simply be removed by zeroing out the mean (zero-wavenumber) component on every update.
    - Since we perform the *complex* FFT of real-valued functions, they can leak energy into the imaginary component of the solution. A real-valued [Hartley Transform](https://en.wikipedia.org/wiki/Hartley_transform) would be better. Instead, we add an extra FFT pass to extract the real component of the solution.
    - The multi-step method is initialized with the same values for both previous steps, rather than implementing a special Backward Euler initialization step.
  </script>
  <script id="14" type="text/markdown">
    The domain has size ${tex`[0, 2 L_x] \times [0, 2 L_y]`}, but the equation is solved in the domain ${tex`[0, 2\pi] \times [0, 2\pi]`} via the rescaling in Chapter 9 of Kalogirou's thesis,

    ${tex.block`x \rarr \frac{L_x}{\pi} x, \;\;\; y \rarr \frac{L_y}{\pi} y, \;\;\; t \rarr \left(\frac{L_x}{\pi}\right)^2 t.`}

    along with the factors ${tex`\nu_1 = \left(\frac{\pi}{L_x}\right)^2`} and ${tex`\nu_2 = \left(\frac{\pi}{L_y}\right)^2`}.
  </script>
  <script id="15" type="text/markdown">
    From Appendix F on page 227, the full second order spatial frequency domain update equation for solution ${tex`\hat{V}`} at step ${tex`n+2`} as a function of the data from previous steps ${tex`n+1`} and ${tex`n`} is

    ${tex.block`\begin{aligned}
    \hat{V}^{n + 2}_{k_1, k_2} =& \frac{1}{\xi_{k_1, k_2}} \left[ (2 + 2c\,dt) \hat{V}^{n+1}_{k_1,k_2} - \left(\frac{1}{2} + c\,dt\right) \hat{V}^n_{k_1,k_2} \right. \\
    & + 2dt \left( \hat{A}^{n+1}_{k_1,k_2} + \frac{\nu_2}{\nu_1} \hat{B}^{n+1}_{k_1,k_2} \right) \\
    & - \left. dt \left( \hat{A}^{n}_{k_1,k_2} + \frac{\nu_2}{\nu_1} \hat{B}^{n}_{k_1,k_2} \right) \right]
    \end{aligned}`}

    where

    ${tex.block`\begin{aligned}
    \hat{A}_{k_1,k_2} &= -\mathscr{F}\left(\frac{1}{2}\left(\frac{\partial v}{\partial x}\right)^2\right), \\
    \hat{B}_{k_1,k_2} &= -\mathscr{F}\left(\frac{1}{2}\left(\frac{\partial v}{\partial y}\right)^2\right)
    \end{aligned}`}

    where ${tex`\mathscr{F}(\cdot)`} represents the spatial Fourier Transform and ${tex`v`} is the spatial domain solution.
  </script>
  <script id="16" type="text/markdown">
    Finally,

    ${tex.block`\begin{aligned}
    \xi_{k_1,k_2} =& \frac{3}{2} + c\,dt - dt\left(k_1^2 + \frac{\nu_1}{\nu_2} k_2^2 \right) \\
    & + \nu_1\,dt\left(k_1^2 + \frac{\nu_2}{\nu_1} k_2^2\right)^2,
    \end{aligned}`}

    using the definition ${tex`c = 1 + \frac{1}{\nu_1}`}.
  </script>
  <script id="17" type="text/markdown">
    At first this update equation seems imposing, but if ${tex`k_1`} and ${tex`k_2`} refer to a particular wavenumber then the above is a simple algebraic expression for each grid point, independent of all others. The only exceptions are the expressions for ${tex`\hat{A}_{k_1,k_2}`} and ${tex`\hat{B}_{k_1,k_2}`}, which represent the solution, differentiated in the frequency domain via multiplication by ${tex`ik_x`} and ${tex`ik_y`}, inverse-FFT'd into the spatial domain, squared, and then FFT'd back into the spatial frequency domain. From there, the rest is tedious but straightforward shuffling of buffers.
  </script>
  <script id="17b" type="text/markdown">
    ## WebGPU implementation

    One might hope GPU programming is plug and play. In practice, there's a lot that can go wrong.

    The first hurdle is simply getting the FFT right. WebGPU lacks a built-in FFT library, meaning you must roll your own using compute shaders. This notebook uses the [Cooley-Tukey](https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm) radix-2 decimation-in-time algorithm, which requires a bit-reversal permutation at the input followed by ${tex`\log_2 N`} stages of butterfly operations. For grid sizes larger than the device's maximum workgroup size (often 256), a hierarchical four-step FFT decomposes the transform into smaller pieces. Even then, getting the indexing, normalization, and twiddle factors all correct takes real effort. If there's any upside, it's that errors tend to be spectacular; it either works or it clearly doesn't.

    Once the FFT works, you have to get all the wavenumbers right. Wavenumber layout in a discrete Fourier transform is not intuitive. The first half contains positive frequencies, but the second half contains negative frequencies in reverse order. Miss a sign or an off-by-one error and the derivatives blow up quickly.

    Another subtle issue is that taking the complex FFT of real-valued data introduces numerical drift. The imaginary part should be exactly zero, but floating point errors slowly leak energy into it. Left unchecked, this can cause the solution to diverge. The workaround is to add an extra pass after each time step that extracts just the real part before transforming back. It adds cost, but it stabilizes the simulation. A properly-implemented real-valued transform like the Hartley transform would avoid this issue entirely.

    Finally, this simulation relies on a healthy dose of *not overthinking it*. The BDF2 method technically requires a special first-order initialization step, but reusing the initial condition for both previous time levels works fine. The uniform buffer management could be more careful about GPU resource lifetimes, but letting them garbage collect naturally is simpler and hasn't caused problems. Sometimes the pragmatic solution is the right one.
  </script>
  <script id="18" type="module">
    import { createWebGPUContext } from './webgpu-context.js';

    const context = await createWebGPUContext();
    const device = context.device;
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();

    invalidation.then(() => device.destroy());
  </script>
  <script id="19" type="module">
    import { createKSPipelines } from './pipeline.js';
    import { executeFFT2D } from './fft.js';
  </script>
  <script id="20" type="module">
    const gridN = N;
    const vec2Size = gridN * gridN * 2 * 4;
    const vec4Size = gridN * gridN * 4 * 4;
    const workgroups = Math.ceil(gridN / 16);
    const bufferUsage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST;
    const dx = [2 * Math.PI / gridN, 2 * Math.PI / gridN];
  </script>
  <script id="21" type="module">
    // Depend on constants
    gridN; vec2Size; dx;

    const pipelines = await createKSPipelines(device, canvasFormat, gridN);

    function runFFT2D(input, output, tempBuffers, forward) {
      executeFFT2D({
        device,
        pipelines: pipelines.fft,
        input,
        output,
        temp: tempBuffers,
        N: gridN,
        forward,
        splitNormalization: true
      });
    }
  </script>
  <script id="22" type="module">
    // Vhat buffers: 3 time levels for BDF2
    const Vhat = [0, 1, 2].map(i => device.createBuffer({
      label: `Vhat[${i}]`,
      size: vec2Size,
      usage: bufferUsage
    }));

    // ABhat buffers: nonlinear terms at 2 time levels
    const ABhat = [0, 1].map(i => device.createBuffer({
      label: `ABhat[${i}]`,
      size: vec4Size,
      usage: bufferUsage
    }));

    // Working buffers
    const V = device.createBuffer({ label: 'V', size: vec2Size, usage: bufferUsage });
    const temp = [0, 1].map(i => device.createBuffer({ label: `temp[${i}]`, size: vec2Size, usage: bufferUsage }));
    const tempVec4 = device.createBuffer({ label: 'tempVec4', size: vec4Size, usage: bufferUsage });
    const VxVy = device.createBuffer({ label: 'VxVy', size: vec2Size, usage: bufferUsage });
    const A = device.createBuffer({ label: 'A', size: vec2Size, usage: bufferUsage });
    const B = device.createBuffer({ label: 'B', size: vec2Size, usage: bufferUsage });
    const Ahat = device.createBuffer({ label: 'Ahat', size: vec2Size, usage: bufferUsage });
    const Bhat = device.createBuffer({ label: 'Bhat', size: vec2Size, usage: bufferUsage });
    const Vreal = device.createBuffer({ label: 'Vreal', size: vec2Size, usage: bufferUsage });

    // Cleanup buffers on invalidation
    // Note: We don't explicitly destroy buffers here because the animation loop
    // may still have pending callbacks that reference them. WebGPU will garbage
    // collect the buffers when there are no more references.
  </script>
  <script id="23" type="module">
    const initParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const diffParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    {
      const data = new ArrayBuffer(16);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 2).set(dx);
      device.queue.writeBuffer(diffParamsBuffer, 0, data);
    }

    const bdfParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const extractRealParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(extractRealParamsBuffer, 0, new Uint32Array([N, N]));

    // New GPU-only nonlinear computation uniform buffers
    const extractMixedDerivativesParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(extractMixedDerivativesParamsBuffer, 0, new Uint32Array([N, N]));

    const computeABParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(computeABParamsBuffer, 0, new Uint32Array([N, N]));

    const packABhatParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(packABhatParamsBuffer, 0, new Uint32Array([N, N]));

    const visParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    // Cleanup on invalidation
    // Note: We don't explicitly destroy buffers here because the animation loop
    // may still have pending callbacks that reference them. WebGPU will garbage
    // collect the buffers when there are no more references.
  </script>
  <script id="24" type="module">
    function generateColorscale(interpolator) {
      const data = new Uint8Array(256 * 4);
      for (let i = 0; i < 256; i++) {
        const t = i / 255;
        const color = d3.rgb(interpolator(t));
        data[i * 4] = Math.round(color.r);
        data[i * 4 + 1] = Math.round(color.g);
        data[i * 4 + 2] = Math.round(color.b);
        data[i * 4 + 3] = 255;
      }
      return data;
    }

    const colorscaleData = {
      Viridis: generateColorscale(d3.interpolateViridis),
      Magma: generateColorscale(d3.interpolateMagma),
      Inferno: generateColorscale(d3.interpolateInferno),
      Plasma: generateColorscale(d3.interpolatePlasma),
      Cividis: generateColorscale(d3.interpolateCividis),
      Greys: generateColorscale(d3.interpolateGreys)
    };

    const colorscaleTexture = device.createTexture({
      size: [256, 1],
      format: 'rgba8unorm',
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
    });

    const colorscaleSampler = device.createSampler({
      magFilter: 'linear',
      minFilter: 'linear'
    });

    // Initialize with default
    device.queue.writeTexture(
      { texture: colorscaleTexture },
      colorscaleData['Magma'],
      { bytesPerRow: 256 * 4 },
      [256, 1]
    );
  </script>
  <script id="25" type="module">
    const canvas = document.createElement('canvas');
    const gpuContext = canvas.getContext('webgpu');

    // Function to resize canvas based on available width and aspect ratio
    function resizeCanvas(availableWidth, ar) {
      const dpr = window.devicePixelRatio || 1;

      // CSS size based on available width, respecting aspect ratio
      let cssW, cssH;
      if (ar >= 1) {
        cssW = availableWidth;
        cssH = Math.floor(availableWidth / ar);
      } else {
        cssH = availableWidth;
        cssW = Math.floor(availableWidth * ar);
      }

      // Physical pixels = CSS pixels * devicePixelRatio
      const physW = Math.floor(cssW * dpr);
      const physH = Math.floor(cssH * dpr);

      canvas.width = physW;
      canvas.height = physH;
      canvas.style.width = `${cssW}px`;
      canvas.style.aspectRatio = `${cssW} / ${cssH}`;

      gpuContext.configure({
        device,
        format: canvasFormat,
        alphaMode: 'opaque'
      });
    }

    // Initial sizing with default aspect ratio (script 26 will update reactively)
    resizeCanvas(width, 1);
  </script>
  <script id="26" type="module">
    // Re-render when width or aspectRatio changes
    width; aspectRatio; initComplete;
    resizeCanvas(width, aspectRatio);
    render();
  </script>
  <script id="27" type="module">
    const simState = {
      timeLevel: 0,
      stepCount: 0
    };

    // Shared params object - updated reactively but read without creating dependencies
    const simParams = {
      Lx: 64,
      aspectRatio: 1,
      n: 1,
      range: 14,
      colorscaleName: 'Magma',
      invert: false
    };
  </script>
  <script id="28" type="module">
    Lx; aspectRatio; n; contrast; colorscaleName; invert;
    simParams.Lx = Lx;
    simParams.aspectRatio = aspectRatio;
    simParams.n = n;
    simParams.contrast = contrast;
    simParams.colorscaleName = colorscaleName;
    simParams.invert = invert;
  </script>
  <script id="29" type="module">
    // Get current simulation parameters from simParams
    function getParams() {
      const Lx = simParams.Lx;
      const L = [Lx, Lx / simParams.aspectRatio];
      const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];
      // Time step scales with grid resolution for stability
      // Base time step at N=256, scale linearly with dx (inversely with N)
      const baseN = 256;
      const dt = 0.18 * nu[0];// * (baseN / N) ** 0.125;
      return { L, nu, dt, dx, N };
    }

    // Update uniform buffers with current params
    // icPeriods is optional - only needed for initialization
    function updateUniforms(icPeriods) {
      const { nu, dt } = getParams();

      // Init params - only write if icPeriods provided (during initialization)
      if (icPeriods !== undefined) {
        const initData = new ArrayBuffer(16);
        new Uint32Array(initData, 0, 2).set([N, N]);
        new Float32Array(initData, 8, 1).set([icPeriods]);
        device.queue.writeBuffer(initParamsBuffer, 0, initData);
      }

      // BDF params
      const bdfData = new ArrayBuffer(32);
      new Uint32Array(bdfData, 0, 2).set([N, N]);
      new Float32Array(bdfData, 8, 2).set(dx);
      new Float32Array(bdfData, 16, 1).set([dt]);
      new Float32Array(bdfData, 24, 2).set(nu);
      device.queue.writeBuffer(bdfParamsBuffer, 0, bdfData);
    }

    // Update visualization uniforms from simParams
    function updateVisUniforms() {
      const data = new ArrayBuffer(16);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 1).set([simParams.contrast / (1 - simParams.contrast)]);
      new Uint32Array(data, 12, 1).set([simParams.invert ? 1 : 0]);
      device.queue.writeBuffer(visParamsBuffer, 0, data);

      // Update colorscale texture
      const csData = colorscaleData[simParams.colorscaleName];
      if (csData) {
        device.queue.writeTexture(
          { texture: colorscaleTexture },
          csData,
          { bytesPerRow: 256 * 4 },
          [256, 1]
        );
      }
    }

    // Initialize simulation with given initial condition periods
    async function initialize(icPeriods) {
      // Wait for any in-flight GPU work to complete before reinitializing buffers
      await device.queue.onSubmittedWorkDone();

      updateUniforms(icPeriods);

      const initBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.initialize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: initParamsBuffer } }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginComputePass();
      pass.setPipeline(pipelines.initialize);
      pass.setBindGroup(0, initBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(V, Vhat[0], temp, true);

      const enc2 = device.createCommandEncoder();
      enc2.copyBufferToBuffer(Vhat[0], 0, Vhat[1], 0, vec2Size);
      device.queue.submit([enc2.finish()]);
      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = 1;
      simState.stepCount = 0;
    }

    // Compute nonlinear terms - GPU only, no CPU readback
    function computeNonlinearTo(vhatIdx, abhatIdx) {
      const VhatIn = Vhat[vhatIdx];
      const ABhatOut = ABhat[abhatIdx];

      // Step 1: Differentiate in frequency domain
      // Vhat -> tempVec4 (contains Vhat and mixed derivatives)
      const diffBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.differentiate,
        entries: [
          { binding: 0, resource: { buffer: VhatIn } },
          { binding: 1, resource: { buffer: tempVec4 } },
          { binding: 2, resource: { buffer: diffParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.differentiate);
      pass.setBindGroup(0, diffBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 2: Extract mixed derivatives from vec4 to vec2
      // tempVec4.zw -> VxVy
      const extractBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.extractMixedDerivatives,
        entries: [
          { binding: 0, resource: { buffer: tempVec4 } },
          { binding: 1, resource: { buffer: VxVy } },
          { binding: 2, resource: { buffer: extractMixedDerivativesParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.extractMixedDerivatives);
      pass.setBindGroup(0, extractBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 3: Inverse FFT to get spatial derivatives
      // VxVy (frequency) -> VxVy (spatial: real=Vx, imag=Vy)
      runFFT2D(VxVy, VxVy, temp, false);

      // Step 4: Compute A and B from spatial derivatives
      // VxVy -> A, B (A = -0.5*Vx^2, B = -0.5*Vy^2)
      const computeABBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.computeAB,
        entries: [
          { binding: 0, resource: { buffer: VxVy } },
          { binding: 1, resource: { buffer: A } },
          { binding: 2, resource: { buffer: B } },
          { binding: 3, resource: { buffer: computeABParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.computeAB);
      pass.setBindGroup(0, computeABBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 5: Forward FFT to get frequency domain
      // A -> Ahat, B -> Bhat
      runFFT2D(A, Ahat, temp, true);
      runFFT2D(B, Bhat, temp, true);

      // Step 6: Pack Ahat and Bhat into ABhat
      // Ahat, Bhat -> ABhat
      const packBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.packABhat,
        entries: [
          { binding: 0, resource: { buffer: Ahat } },
          { binding: 1, resource: { buffer: Bhat } },
          { binding: 2, resource: { buffer: ABhatOut } },
          { binding: 3, resource: { buffer: packABhatParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.packABhat);
      pass.setBindGroup(0, packBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);
    }

    // Run one BDF2 step
    async function step() {
      // Update BDF params in case Lx changed
      updateUniforms();

      const idx0 = (simState.timeLevel - 1 + 3) % 3;
      const idx1 = simState.timeLevel % 3;
      const idx2 = (simState.timeLevel + 1) % 3;

      computeNonlinearTo(idx0, 0);
      computeNonlinearTo(idx1, 1);

      const bdfBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.bdfUpdate,
        entries: [
          { binding: 0, resource: { buffer: Vhat[idx0] } },
          { binding: 1, resource: { buffer: Vhat[idx1] } },
          { binding: 2, resource: { buffer: ABhat[0] } },
          { binding: 3, resource: { buffer: ABhat[1] } },
          { binding: 4, resource: { buffer: Vhat[idx2] } },
          { binding: 5, resource: { buffer: bdfParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.bdfUpdate);
      pass.setBindGroup(0, bdfBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vhat[idx2], V, temp, false);

      const extractBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.extractReal,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: Vreal } },
          { binding: 2, resource: { buffer: extractRealParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.extractReal);
      pass.setBindGroup(0, extractBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vreal, Vhat[idx2], temp, true);

      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = (simState.timeLevel + 1) % 3;
      simState.stepCount++;
    }

    // Render current state
    function render() {
      updateVisUniforms();

      const currentVhat = Vhat[simState.timeLevel % 3];
      runFFT2D(currentVhat, V, temp, false);

      const visBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.visualize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: visParamsBuffer } },
          { binding: 2, resource: colorscaleTexture.createView() },
          { binding: 3, resource: colorscaleSampler }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginRenderPass({
        colorAttachments: [{
          view: gpuContext.getCurrentTexture().createView(),
          loadOp: 'clear',
          storeOp: 'store',
          clearValue: { r: 0, g: 0, b: 0, a: 1 }
        }]
      });
      pass.setPipeline(pipelines.visualize);
      pass.setBindGroup(0, visBindGroup);
      pass.draw(6);
      pass.end();
      device.queue.submit([enc.finish()]);
    }
  </script>
  <script id="30" type="module">
    // Depend on n and restart so we reinitialize when either changes
    n; restart;
    await initialize(n);
    render();

    // Export a token that changes each time this cell runs
    // Animation loop depends on this to wait for init to complete
    const initComplete = { n, restart };
  </script>
  <script id="31" type="module">
    // Depend on step/render (for N changes), initComplete (for n changes), and restart
    // restart dependency ensures animation loop stops BEFORE reinitialization starts
    step; render; initComplete; restart;

    let animFrameId = null;
    let hasError = false;

    async function animationLoop() {
      if (hasError) return;  // Stop if we encountered an error

      try {
        if (simulate) {
          for (let i = 0; i < 2; i++) {
            await step();
          }
          render();
        }
        animFrameId = requestAnimationFrame(animationLoop);
      } catch (e) {
        hasError = true;
        console.error('Animation loop error:', e);
      }
    }

    animFrameId = requestAnimationFrame(animationLoop);

    invalidation.then(() => {
      hasError = true;  // Signal the loop to stop
      if (animFrameId !== null) {
        cancelAnimationFrame(animFrameId);
        animFrameId = null;
      }
    });
  </script>
  <script id="32" type="module">
    // Re-render when vis params change (params-update already updated simParams)
    contrast; colorscaleName; invert; initComplete;
    render();
  </script>
  <script id="33" type="module">
    const statusEl = html`<p><em>Step: <span id="step-count">0</span></em></p>`;

    let statusFrameId = null;

    function updateStatus() {
      const el = document.getElementById('step-count');
      if (el) el.textContent = simState.stepCount;
      statusFrameId = requestAnimationFrame(updateStatus);
    }

    statusFrameId = requestAnimationFrame(updateStatus);

    invalidation.then(() => {
      if (statusFrameId !== null) {
        cancelAnimationFrame(statusFrameId);
        statusFrameId = null;
      }
    });
  </script>
</notebook>
