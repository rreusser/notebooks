<!doctype html>
<notebook theme="air">
  <title>Simulating the 2D Kuramoto-Sivashinsky Equation in WebGPU</title>
  <script id="1" type="text/markdown">
    # Simulating the 2D Kuramoto-Sivashinsky Equation in WebGPU

    This notebook implements on the GPU a two-dimensional solution of the [Kuramoto-Sivashinsky equation](https://encyclopediaofmath.org/wiki/Kuramoto-Sivashinsky_equation) (KSE),

    ${tex.block`u_t + \frac{1}{2}|\nabla u|^2 + \nabla^2 u + \nabla^4 u = 0.`}

    The KSE arises in a number of contexts and was rediscovered by Kuramoto while researching diffusion-induced flame front instabilities. It is one of the simplest partial differential equations exhibiting complicated dynamics, displaying chaotic behavior in large domains.

    For the fully immersive version, see [the WebGL visualization here](https://rreusser.github.io/kuramoto-sivashinsky/). This page explores modernization to WebGPU and [Observable Notebook Kit](https://observablehq.com/notebook-kit/kit), as well as adding cleanup like plot axes (at last!). Also, you may or may not like this, I might lose followers, etc., but I converted this notebook from WebGL 1 in part way of Claude Code, using my experimental [MCP server for Observable Notebook Kit](https://github.com/rreusser/mcp-observable-notebookkit-debug). It implements a small server which controls an in-browser dev preview over a WebSocket, querying runtime outputs, modifying control inputs, analyzing the variable dependency graph, and even analyzing image output. I'm not religious about AI, and that's that.
  </script>
  <script id="10" type="module">
    const L = [Lx, Lx / aspectRatio];
    const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];

    display(md`

As far as the simulation goes, the factors ${tex`\nu_1 = (\pi/L_x)^2`} and ${tex`\nu_2 = (\pi/L_y)^2`} describe the length scale in each dimension. Chaotic behavior occurs when these factors are small. When either factor approaches order unity, the dynamics simplify in that direction, effectively reducing the solution to one dimension.

Based on the config below, we solve the problem in the doubly periodic domain, ${tex`[0, ${L[0].toFixed(1)}] \times [0, ${L[1].toFixed(1)}]`} with ${tex`\nu_1 = ${nu[0].toFixed(6)}`} and ${tex`\nu_2 = ${nu[1].toFixed(6)}.`}
`);
  </script>
  <script id="3" type="module">
    // With hierarchical FFT, we can support sizes up to maxWorkgroupSize^2
    // For N > maxWorkgroupSize, we decompose N = R × C where C ≤ maxWorkgroupSize
    const maxWorkgroupSize = device.limits.maxComputeWorkgroupSizeX;

    // All sizes we want to support
    const allSizes = [32, 64, 128, 256, 512, 1024];

    // Filter to sizes that are either:
    // - ≤ maxWorkgroupSize (handled by simple FFT)
    // - Decomposable as R × C where C ≤ maxWorkgroupSize and R is power of 2
    const validSizes = allSizes.filter(n => {
      if (n <= maxWorkgroupSize) return true;
      // For large N, check if we can factor it appropriately
      const C = maxWorkgroupSize;
      const R = n / C;
      return Number.isInteger(R) && (R & (R - 1)) === 0;
    });

    const gridSizeOptions = validSizes.map(n => `${n}×${n}`);

    // Default to 512 for testing hierarchical FFT
    const defaultN = 512;

    const NInput = Inputs.select(gridSizeOptions, {
      value: `${defaultN}×${defaultN}`,
      label: 'Grid size, N'
    });
    const NString = view(NInput);
  </script>
  <script id="3b" type="module">
    const N = parseInt(NString.split('×')[0]);
  </script>
  <script id="4" type="module">
    // Max domain size scales with grid resolution (N/2)
    const maxLx = N / 2;
    const LxInput = Inputs.range([1, maxLx], {
      step: 0.1,
      transform: Math.log,
      value: Math.min(64, maxLx),
      label: html`Domain size, ${tex`L_x`}`
    });
    const Lx = view(LxInput);

    const aspectRatioInput = Inputs.range([1.0, 10], {
      step: 0.01,
      value: 1,
      transform: Math.log,
      label: html`Aspect ratio, ${tex`L_x / L_y`}`
    });
    const aspectRatio = view(aspectRatioInput);
    const nInput = Inputs.range([1, 8], {
      step: 1,
      value: 1,
      label: 'Initial condition periods, n'
    });
    const n = view(nInput);
  </script>
  <script id="6" type="module">
    const simulateInput = Inputs.toggle({ label: 'Simulate', value: ['Simulate'] });
    const simulate = view(simulateInput);
    const restartInput = Inputs.button('Restart');
    const restart = view(restartInput);
  </script>
  <script id="7" type="module">
    // Create plot overlay with axes (updated reactively in script 26)
    function createPlotOverlay(dims) {
      const { totalW, totalH, Lx, Ly } = dims;
      const plot = Plot.plot({
        width: totalW,
        height: totalH,
        marginTop: margins.top,
        marginRight: margins.right,
        marginBottom: margins.bottom,
        marginLeft: margins.left,
        style: { background: 'transparent' },
        x: { domain: [0, Lx], label: 'x' },
        y: { domain: [0, Ly], label: 'y' },
        marks: []
      });
      plot.style.position = 'absolute';
      plot.style.left = '0';
      plot.style.top = '0';
      plot.style.pointerEvents = 'none';
      return plot;
    }

    let plotOverlay = createPlotOverlay(resizeCanvas(width, 1, 64));
    container.appendChild(plotOverlay);

    function updatePlotOverlay(dims) {
      const newPlot = createPlotOverlay(dims);
      plotOverlay.replaceWith(newPlot);
      plotOverlay = newPlot;
    }

    const figure = html`<figure style="display: flex; justify-content: center; margin: 0;">${container}</figure>`;
    display(figure);
  </script>
  <script id="8" type="module">
    display(statusEl);
  </script>
  <script id="9" type="module">
    const contrastInput = Inputs.range([0, 1], {
      step: 0.01,
      value: 0.5,
      label: 'Contrast'
    });
    const contrast = view(contrastInput);

    const colorscaleNameInput = Inputs.select(
      ['Viridis', 'Magma', 'Inferno', 'Plasma', 'Cividis', 'Greys'],
      { value: 'Magma', label: 'Colorscale' }
    );
    const colorscaleName = view(colorscaleNameInput);

    const invertInput = Inputs.toggle({ label: 'Invert colorscale', value: true });
    const invert = view(invertInput);
  </script>
  <script id="11" type="text/markdown">
    ## Solution method

    This notebook follows the solution method outlined in [Kalogirou's thesis](https://spiral.imperial.ac.uk/bitstream/10044/1/25067/1/Kalogirou-A-2013-PhD-Thesis.pdf), particularly equations (F.8) - (F.10). The solution uses an implicit-explicit [Backward Differentiation Formula](https://en.wikipedia.org/wiki/Backward_differentiation_formula) in the spatial frequency domain.
  </script>
  <script id="12" type="text/markdown">
    The equation is solved in the spatial frequency domain, with the exception of the nonlinear term ${tex`\frac{1}{2}|\nabla u|^2`} which requires computing the gradient while transforming back to the spatial domain, then squaring, then transforming back to the frequency domain.
  </script>
  <script id="13" type="text/markdown">
    A few implementation notes:

    - Equation (F.10) seems to be missing a factor of ${tex`dt`} in the biharmonic term.
    - Since all terms include derivatives, the offset of ${tex`u`} has no effect and can simply be removed by zeroing out the mean (zero-wavenumber) component on every update.
    - The multi-step method is initialized with the same values for both previous steps, rather than implementing a special Backward Euler initialization step.
  </script>
  <script id="14" type="text/markdown">
    The domain has size ${tex`[0, 2 L_x] \times [0, 2 L_y]`}, but the equation is solved in the domain ${tex`[0, 2\pi] \times [0, 2\pi]`} via the rescaling in Chapter 9 of Kalogirou's thesis,

    ${tex.block`x \rarr \frac{L_x}{\pi} x, \;\;\; y \rarr \frac{L_y}{\pi} y, \;\;\; t \rarr \left(\frac{L_x}{\pi}\right)^2 t.`}

    along with the factors ${tex`\nu_1 = \left(\frac{\pi}{L_x}\right)^2`} and ${tex`\nu_2 = \left(\frac{\pi}{L_y}\right)^2`}.
  </script>
  <script id="15" type="text/markdown">
    From Appendix F on page 227, the full second order spatial frequency domain update equation for solution ${tex`\hat{V}`} at step ${tex`n+2`} as a function of the data from previous steps ${tex`n+1`} and ${tex`n`} is

    ${tex.block`\begin{aligned}
    \hat{V}^{n + 2}_{k_1, k_2} =& \frac{1}{\xi_{k_1, k_2}} \left[ (2 + 2c\,dt) \hat{V}^{n+1}_{k_1,k_2} - \left(\frac{1}{2} + c\,dt\right) \hat{V}^n_{k_1,k_2} \right. \\
    & + 2dt \left( \hat{A}^{n+1}_{k_1,k_2} + \frac{\nu_2}{\nu_1} \hat{B}^{n+1}_{k_1,k_2} \right) \\
    & - \left. dt \left( \hat{A}^{n}_{k_1,k_2} + \frac{\nu_2}{\nu_1} \hat{B}^{n}_{k_1,k_2} \right) \right]
    \end{aligned}`}

    where

    ${tex.block`\begin{aligned}
    \hat{A}_{k_1,k_2} &= -\mathscr{F}\left(\frac{1}{2}\left(\frac{\partial v}{\partial x}\right)^2\right), \\
    \hat{B}_{k_1,k_2} &= -\mathscr{F}\left(\frac{1}{2}\left(\frac{\partial v}{\partial y}\right)^2\right)
    \end{aligned}`}

    where ${tex`\mathscr{F}(\cdot)`} represents the spatial Fourier Transform and ${tex`v`} is the spatial domain solution.
  </script>
  <script id="16" type="text/markdown">
    Finally,

    ${tex.block`\begin{aligned}
    \xi_{k_1,k_2} =& \frac{3}{2} + c\,dt - dt\left(k_1^2 + \frac{\nu_2}{\nu_1} k_2^2 \right) \\
    & + \nu_1\,dt\left(k_1^2 + \frac{\nu_2}{\nu_1} k_2^2\right)^2,
    \end{aligned}`}

    using the definition ${tex`c = 1 + \frac{1}{\nu_1}`}.
  </script>
  <script id="17" type="text/markdown">
    At first this update equation seems imposing, but if ${tex`k_1`} and ${tex`k_2`} refer to a particular wavenumber then the above is a simple algebraic expression for each grid point, independent of all others. The only exceptions are the expressions for ${tex`\hat{A}_{k_1,k_2}`} and ${tex`\hat{B}_{k_1,k_2}`}, which represent the solution, differentiated in the frequency domain via multiplication by ${tex`ik_x`} and ${tex`ik_y`}, inverse-FFT'd into the spatial domain, squared, and then FFT'd back into the spatial frequency domain. From there, the rest is tedious but straightforward shuffling of buffers.
  </script>
  <script id="17b" type="text/markdown">
    ## WebGPU implementation

    WebGPU has no built-in FFT, so this notebook implements [Cooley-Tukey](https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm) radix-2 in compute shaders: bit-reversal at the input, then ${tex`\log_2 N`} butterfly stages. For grids larger than the maximum workgroup size (256 on most devices), a hierarchical four-step FFT breaks the transform into smaller pieces. Getting the indexing, normalization, and twiddle factors right is tedious, but at least FFT bugs are obvious.

    Wavenumber layout in DFTs is also error-prone. The first half of the output contains positive frequencies; the second half contains negative frequencies in reverse order. A wrong sign or off-by-one index makes derivatives blow up fast.

    Taking the complex FFT of real data causes numerical drift. The imaginary part should stay zero, but floating point errors leak energy into it over time, eventually destabilizing the solution. The fix is an extra pass per time step to extract the real part before transforming back. A real-valued [Hartley transform](https://en.wikipedia.org/wiki/Hartley_transform) would avoid this.
  </script>
  <script id="18" type="module">
    import { createWebGPUContext } from './webgpu-context.js';

    const context = await createWebGPUContext();
    const device = context.device;
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();

    invalidation.then(() => device.destroy());
  </script>
  <script id="19" type="module">
    import { createKSPipelines } from './pipeline.js';
    import { executeFFT2D } from './fft.js';
  </script>
  <script id="20" type="module">
    const gridN = N;
    const vec2Size = gridN * gridN * 2 * 4;
    const vec4Size = gridN * gridN * 4 * 4;
    const workgroups = Math.ceil(gridN / 16);
    const bufferUsage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST;
    const dx = [2 * Math.PI / gridN, 2 * Math.PI / gridN];
  </script>
  <script id="21" type="module">
    // Depend on constants
    gridN; vec2Size; dx;

    const pipelines = await createKSPipelines(device, canvasFormat, gridN);

    function runFFT2D(input, output, tempBuffers, forward) {
      executeFFT2D({
        device,
        pipelines: pipelines.fft,
        input,
        output,
        temp: tempBuffers,
        N: gridN,
        forward,
        splitNormalization: true
      });
    }
  </script>
  <script id="22" type="module">
    // Vhat buffers: 3 time levels for BDF2
    const Vhat = [0, 1, 2].map(i => device.createBuffer({
      label: `Vhat[${i}]`,
      size: vec2Size,
      usage: bufferUsage
    }));

    // ABhat buffers: nonlinear terms at 2 time levels
    const ABhat = [0, 1].map(i => device.createBuffer({
      label: `ABhat[${i}]`,
      size: vec4Size,
      usage: bufferUsage
    }));

    // Working buffers
    const V = device.createBuffer({ label: 'V', size: vec2Size, usage: bufferUsage });
    const temp = [0, 1].map(i => device.createBuffer({ label: `temp[${i}]`, size: vec2Size, usage: bufferUsage }));
    const tempVec4 = device.createBuffer({ label: 'tempVec4', size: vec4Size, usage: bufferUsage });
    const VxVy = device.createBuffer({ label: 'VxVy', size: vec2Size, usage: bufferUsage });
    const A = device.createBuffer({ label: 'A', size: vec2Size, usage: bufferUsage });
    const B = device.createBuffer({ label: 'B', size: vec2Size, usage: bufferUsage });
    const Ahat = device.createBuffer({ label: 'Ahat', size: vec2Size, usage: bufferUsage });
    const Bhat = device.createBuffer({ label: 'Bhat', size: vec2Size, usage: bufferUsage });
    const Vreal = device.createBuffer({ label: 'Vreal', size: vec2Size, usage: bufferUsage });

    // Cleanup buffers on invalidation
    // Note: We don't explicitly destroy buffers here because the animation loop
    // may still have pending callbacks that reference them. WebGPU will garbage
    // collect the buffers when there are no more references.
  </script>
  <script id="23" type="module">
    const initParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const diffParamsBuffer = device.createBuffer({
      size: 16,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    {
      const data = new ArrayBuffer(16);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 2).set(dx);
      device.queue.writeBuffer(diffParamsBuffer, 0, data);
    }

    const bdfParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    const extractRealParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(extractRealParamsBuffer, 0, new Uint32Array([N, N]));

    // New GPU-only nonlinear computation uniform buffers
    const extractMixedDerivativesParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(extractMixedDerivativesParamsBuffer, 0, new Uint32Array([N, N]));

    const computeABParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(computeABParamsBuffer, 0, new Uint32Array([N, N]));

    const packABhatParamsBuffer = device.createBuffer({
      size: 8,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    device.queue.writeBuffer(packABhatParamsBuffer, 0, new Uint32Array([N, N]));

    const visParamsBuffer = device.createBuffer({
      size: 32,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    // Cleanup on invalidation
    // Note: We don't explicitly destroy buffers here because the animation loop
    // may still have pending callbacks that reference them. WebGPU will garbage
    // collect the buffers when there are no more references.
  </script>
  <script id="24" type="module">
    function generateColorscale(interpolator) {
      const data = new Uint8Array(256 * 4);
      for (let i = 0; i < 256; i++) {
        const t = i / 255;
        const color = d3.rgb(interpolator(t));
        data[i * 4] = Math.round(color.r);
        data[i * 4 + 1] = Math.round(color.g);
        data[i * 4 + 2] = Math.round(color.b);
        data[i * 4 + 3] = 255;
      }
      return data;
    }

    const colorscaleData = {
      Viridis: generateColorscale(d3.interpolateViridis),
      Magma: generateColorscale(d3.interpolateMagma),
      Inferno: generateColorscale(d3.interpolateInferno),
      Plasma: generateColorscale(d3.interpolatePlasma),
      Cividis: generateColorscale(d3.interpolateCividis),
      Greys: generateColorscale(d3.interpolateGreys)
    };

    const colorscaleTexture = device.createTexture({
      size: [256, 1],
      format: 'rgba8unorm',
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
    });

    const colorscaleSampler = device.createSampler({
      magFilter: 'linear',
      minFilter: 'linear'
    });

    // Initialize with default
    device.queue.writeTexture(
      { texture: colorscaleTexture },
      colorscaleData['Magma'],
      { bytesPerRow: 256 * 4 },
      [256, 1]
    );
  </script>
  <script id="25" type="module">
    // Plot margins - canvas will be positioned inside these
    const margins = { top: 5, right: 5, bottom: 25, left: 35 };

    // Container for stacking canvas and plot
    const container = html`<div style="position: relative;"></div>`;

    // WebGPU canvas - will be positioned absolutely within container
    // Hidden initially until initialization completes
    const canvas = document.createElement('canvas');
    canvas.style.position = 'absolute';
    canvas.style.visibility = 'hidden';
    const gpuContext = canvas.getContext('webgpu');

    // Function to resize canvas and container based on available width and aspect ratio
    // Returns the plot dimensions for creating the overlay
    function resizeCanvas(availableWidth, ar, Lx) {
      const dpr = window.devicePixelRatio || 1;
      const Ly = Lx / ar;

      // Total container size (plot area + margins)
      // Canvas area dimensions (inside margins)
      let canvasW, canvasH;
      const maxCanvasW = availableWidth - margins.left - margins.right;

      if (ar >= 1) {
        canvasW = maxCanvasW;
        canvasH = Math.floor(maxCanvasW / ar);
      } else {
        canvasH = maxCanvasW;
        canvasW = Math.floor(maxCanvasW * ar);
      }

      const totalW = canvasW + margins.left + margins.right;
      const totalH = canvasH + margins.top + margins.bottom;

      // Size container
      container.style.width = `${totalW}px`;
      container.style.height = `${totalH}px`;

      // Position and size canvas within container
      canvas.style.left = `${margins.left}px`;
      canvas.style.top = `${margins.top}px`;
      canvas.style.width = `${canvasW}px`;
      canvas.style.height = `${canvasH}px`;

      // Physical pixels for WebGPU
      canvas.width = Math.floor(canvasW * dpr);
      canvas.height = Math.floor(canvasH * dpr);

      gpuContext.configure({
        device,
        format: canvasFormat,
        alphaMode: 'opaque'
      });

      return { totalW, totalH, canvasW, canvasH, Lx, Ly };
    }

    // Initial sizing
    resizeCanvas(width, 1, 64);
    container.appendChild(canvas);
  </script>
  <script id="26" type="module">
    // Re-render when width, aspectRatio, or Lx changes
    // Also show canvas after initialization completes
    width; aspectRatio; Lx; initComplete;
    const dims = resizeCanvas(width, aspectRatio, Lx);
    updatePlotOverlay(dims);
    render();
    canvas.style.visibility = 'visible';
  </script>
  <script id="27" type="module">
    const simState = {
      timeLevel: 0,
      time: 0,
      stepCount: 0
    };

    // Shared params object - updated reactively but read without creating dependencies
    const simParams = {
      Lx: 64,
      aspectRatio: 1,
      n: 1,
      range: 14,
      colorscaleName: 'Magma',
      invert: false
    };
  </script>
  <script id="28" type="module">
    Lx; aspectRatio; n; contrast; colorscaleName; invert;
    simParams.Lx = Lx;
    simParams.aspectRatio = aspectRatio;
    simParams.n = n;
    simParams.contrast = contrast;
    simParams.colorscaleName = colorscaleName;
    simParams.invert = invert;
  </script>
  <script id="29" type="module">
    // Get current simulation parameters from simParams
    function getParams() {
      const Lx = simParams.Lx;
      const L = [Lx, Lx / simParams.aspectRatio];
      const nu = [Math.pow(Math.PI / L[0], 2), Math.pow(Math.PI / L[1], 2)];
      // Time step scales with grid resolution for stability
      // Base time step at N=256, scale linearly with dx (inversely with N)
      const baseN = 256;
      const dt = 0.18 * nu[0];// * (baseN / N) ** 0.125;
      return { L, nu, dt, dx, N };
    }

    // Update uniform buffers with current params
    // icPeriods is optional - only needed for initialization
    function updateUniforms(icPeriods) {
      const { nu, dt } = getParams();

      // Init params - only write if icPeriods provided (during initialization)
      if (icPeriods !== undefined) {
        const initData = new ArrayBuffer(16);
        new Uint32Array(initData, 0, 2).set([N, N]);
        new Float32Array(initData, 8, 1).set([icPeriods]);
        device.queue.writeBuffer(initParamsBuffer, 0, initData);
      }

      // BDF params
      const bdfData = new ArrayBuffer(32);
      new Uint32Array(bdfData, 0, 2).set([N, N]);
      new Float32Array(bdfData, 8, 2).set(dx);
      new Float32Array(bdfData, 16, 1).set([dt]);
      new Float32Array(bdfData, 24, 2).set(nu);
      device.queue.writeBuffer(bdfParamsBuffer, 0, bdfData);
    }

    // Update visualization uniforms from simParams
    function updateVisUniforms() {
      const data = new ArrayBuffer(16);
      new Uint32Array(data, 0, 2).set([N, N]);
      new Float32Array(data, 8, 1).set([simParams.contrast / (1 - simParams.contrast)]);
      new Uint32Array(data, 12, 1).set([simParams.invert ? 1 : 0]);
      device.queue.writeBuffer(visParamsBuffer, 0, data);

      // Update colorscale texture
      const csData = colorscaleData[simParams.colorscaleName];
      if (csData) {
        device.queue.writeTexture(
          { texture: colorscaleTexture },
          csData,
          { bytesPerRow: 256 * 4 },
          [256, 1]
        );
      }
    }

    // Initialize simulation with given initial condition periods
    async function initialize(icPeriods) {
      // Wait for any in-flight GPU work to complete before reinitializing buffers
      await device.queue.onSubmittedWorkDone();

      updateUniforms(icPeriods);

      const initBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.initialize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: initParamsBuffer } }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginComputePass();
      pass.setPipeline(pipelines.initialize);
      pass.setBindGroup(0, initBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(V, Vhat[0], temp, true);

      const enc2 = device.createCommandEncoder();
      enc2.copyBufferToBuffer(Vhat[0], 0, Vhat[1], 0, vec2Size);
      device.queue.submit([enc2.finish()]);
      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = 1;
      simState.time = 0;
      simState.stepCount = 0;
    }

    // Compute nonlinear terms - GPU only, no CPU readback
    function computeNonlinearTo(vhatIdx, abhatIdx) {
      const VhatIn = Vhat[vhatIdx];
      const ABhatOut = ABhat[abhatIdx];

      // Step 1: Differentiate in frequency domain
      // Vhat -> tempVec4 (contains Vhat and mixed derivatives)
      const diffBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.differentiate,
        entries: [
          { binding: 0, resource: { buffer: VhatIn } },
          { binding: 1, resource: { buffer: tempVec4 } },
          { binding: 2, resource: { buffer: diffParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.differentiate);
      pass.setBindGroup(0, diffBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 2: Extract mixed derivatives from vec4 to vec2
      // tempVec4.zw -> VxVy
      const extractBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.extractMixedDerivatives,
        entries: [
          { binding: 0, resource: { buffer: tempVec4 } },
          { binding: 1, resource: { buffer: VxVy } },
          { binding: 2, resource: { buffer: extractMixedDerivativesParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.extractMixedDerivatives);
      pass.setBindGroup(0, extractBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 3: Inverse FFT to get spatial derivatives
      // VxVy (frequency) -> VxVy (spatial: real=Vx, imag=Vy)
      runFFT2D(VxVy, VxVy, temp, false);

      // Step 4: Compute A and B from spatial derivatives
      // VxVy -> A, B (A = -0.5*Vx^2, B = -0.5*Vy^2)
      const computeABBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.computeAB,
        entries: [
          { binding: 0, resource: { buffer: VxVy } },
          { binding: 1, resource: { buffer: A } },
          { binding: 2, resource: { buffer: B } },
          { binding: 3, resource: { buffer: computeABParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.computeAB);
      pass.setBindGroup(0, computeABBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      // Step 5: Forward FFT to get frequency domain
      // A -> Ahat, B -> Bhat
      runFFT2D(A, Ahat, temp, true);
      runFFT2D(B, Bhat, temp, true);

      // Step 6: Pack Ahat and Bhat into ABhat
      // Ahat, Bhat -> ABhat
      const packBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.packABhat,
        entries: [
          { binding: 0, resource: { buffer: Ahat } },
          { binding: 1, resource: { buffer: Bhat } },
          { binding: 2, resource: { buffer: ABhatOut } },
          { binding: 3, resource: { buffer: packABhatParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.packABhat);
      pass.setBindGroup(0, packBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);
    }

    // Run one BDF2 step
    async function step() {
      // Update BDF params in case Lx changed
      updateUniforms();

      const idx0 = (simState.timeLevel - 1 + 3) % 3;
      const idx1 = simState.timeLevel % 3;
      const idx2 = (simState.timeLevel + 1) % 3;

      computeNonlinearTo(idx0, 0);
      computeNonlinearTo(idx1, 1);

      const bdfBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.bdfUpdate,
        entries: [
          { binding: 0, resource: { buffer: Vhat[idx0] } },
          { binding: 1, resource: { buffer: Vhat[idx1] } },
          { binding: 2, resource: { buffer: ABhat[0] } },
          { binding: 3, resource: { buffer: ABhat[1] } },
          { binding: 4, resource: { buffer: Vhat[idx2] } },
          { binding: 5, resource: { buffer: bdfParamsBuffer } }
        ]
      });

      let enc = device.createCommandEncoder();
      let pass = enc.beginComputePass();
      pass.setPipeline(pipelines.bdfUpdate);
      pass.setBindGroup(0, bdfBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vhat[idx2], V, temp, false);

      const extractBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.extractReal,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: Vreal } },
          { binding: 2, resource: { buffer: extractRealParamsBuffer } }
        ]
      });

      enc = device.createCommandEncoder();
      pass = enc.beginComputePass();
      pass.setPipeline(pipelines.extractReal);
      pass.setBindGroup(0, extractBindGroup);
      pass.dispatchWorkgroups(workgroups, workgroups);
      pass.end();
      device.queue.submit([enc.finish()]);

      runFFT2D(Vreal, Vhat[idx2], temp, true);

      await device.queue.onSubmittedWorkDone();

      simState.timeLevel = (simState.timeLevel + 1) % 3;
      simState.time += getParams().dt;
      simState.stepCount++;
    }

    // Render current state
    function render() {
      updateVisUniforms();

      const currentVhat = Vhat[simState.timeLevel % 3];
      runFFT2D(currentVhat, V, temp, false);

      const visBindGroup = device.createBindGroup({
        layout: pipelines.bindGroupLayouts.visualize,
        entries: [
          { binding: 0, resource: { buffer: V } },
          { binding: 1, resource: { buffer: visParamsBuffer } },
          { binding: 2, resource: colorscaleTexture.createView() },
          { binding: 3, resource: colorscaleSampler }
        ]
      });

      const enc = device.createCommandEncoder();
      const pass = enc.beginRenderPass({
        colorAttachments: [{
          view: gpuContext.getCurrentTexture().createView(),
          loadOp: 'clear',
          storeOp: 'store',
          clearValue: { r: 0, g: 0, b: 0, a: 1 }
        }]
      });
      pass.setPipeline(pipelines.visualize);
      pass.setBindGroup(0, visBindGroup);
      pass.draw(6);
      pass.end();
      device.queue.submit([enc.finish()]);
    }
  </script>
  <script id="30" type="module">
    // Depend on n and restart so we reinitialize when either changes
    n; restart;
    await initialize(n);
    render();

    // Export a token that changes each time this cell runs
    // Animation loop depends on this to wait for init to complete
    const initComplete = { n, restart };
  </script>
  <script id="31" type="module">
    // Depend on step/render (for N changes) and initComplete (for n/restart changes)
    // initComplete changes when restart changes, so no direct restart dependency needed
    step; render; initComplete;

    let animFrameId = null;
    let hasError = false;

    async function animationLoop() {
      if (hasError) return;  // Stop if we encountered an error

      try {
        if (simulate) {
          for (let i = 0; i < 2; i++) {
            await step();
          }
          render();
        }
        animFrameId = requestAnimationFrame(animationLoop);
      } catch (e) {
        hasError = true;
        console.error('Animation loop error:', e);
      }
    }

    animFrameId = requestAnimationFrame(animationLoop);

    invalidation.then(() => {
      hasError = true;  // Signal the loop to stop
      if (animFrameId !== null) {
        cancelAnimationFrame(animFrameId);
        animFrameId = null;
      }
    });
  </script>
  <script id="32" type="module">
    // Re-render when vis params change (params-update already updated simParams)
    contrast; colorscaleName; invert; initComplete;
    render();
  </script>
  <script id="33" type="module">
    const statusEl = html`<p><em>t = <span id="sim-time">0</span>, step = <span id="sim-step">0</span></em></p>`;

    let statusFrameId = null;

    function updateStatus() {
      const timeEl = document.getElementById('sim-time');
      const stepEl = document.getElementById('sim-step');
      if (timeEl) timeEl.textContent = simState.time.toFixed(4);
      if (stepEl) stepEl.textContent = simState.stepCount;
      statusFrameId = requestAnimationFrame(updateStatus);
    }

    statusFrameId = requestAnimationFrame(updateStatus);

    invalidation.then(() => {
      if (statusFrameId !== null) {
        cancelAnimationFrame(statusFrameId);
        statusFrameId = null;
      }
    });
  </script>
</notebook>
